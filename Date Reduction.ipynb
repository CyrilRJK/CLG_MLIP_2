{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credits to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] https://www.kaggle.com/mayer79/m5-forecast-keras-with-categorical-embeddings-v2 \n",
    "\n",
    "[2] https://www.kaggle.com/ragnar123/very-fst-model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduce Memory Usage "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this function on dataframes to reduce the memory usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Got from: [1]\n",
    "'''\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create file to store encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_file = open('encoders', 'wb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Got from: [1]\n",
    "'''\n",
    "path = \"../input/m5-forecasting-accuracy\"\n",
    "\n",
    "calendar = pd.read_csv(os.path.join(path, \"calendar.csv\"))\n",
    "selling_prices = pd.read_csv(os.path.join(path, \"sell_prices.csv\"))\n",
    "sample_submission = pd.read_csv(os.path.join(path, \"sample_submission.csv\"))\n",
    "sales = pd.read_csv(os.path.join(path, \"sales_train_validation.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar['day'] = [int(x[-2:]) for x in calendar.date]\n",
    "calendar = calendar[((calendar.month==4) & (calendar.day>=25)) | (calendar.month==5) | ((calendar.month==6) & (calendar.day<=19))]\n",
    "calendar.drop(['day'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar['daytype'] = [x[-5:] for x in calendar.date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calendar.daytype.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to  0.01 Mb (79.5% reduction)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Got from: [1]\n",
    "- The columns \"Date\" and \"Weekday\" are dropped as they contain redundant information.\n",
    "- Normally, the column \"d\" is like \"d_1,d_2,...\". Make it \"1,2,..\" and the type integer\n",
    "- If there is no event (I think), there is NA. We will replace them with \"NoEvent\" string. Originally, it was replaced with\n",
    "  \"missing\", but I don't think it makes sense as I don't think there is missing information, I think they just left \n",
    "  the days without any event as NA.\n",
    "- We enumerate most of the columns:\n",
    "    - We do not enumerate \"d\" and \"wm_yr_weak\" because we will use these columns for joins.\n",
    "    - Why do we enumerate month and day? I think it is because they start from 1, not 0.\n",
    "    - Originally, the binary columns \"snap_X\" were also enumerated. I don't think it is necessary. The only neccessary step\n",
    "      was to convert their type from int64 to int as it uses less space; but reduce_mem_usage will take care of that.\n",
    "- I would suggest saving the OrdinalEncoder in case we need to reverse the transformations\n",
    "'''\n",
    "def prep_calendar(df,encoder_file):\n",
    "    df = df.drop([\"date\", \"weekday\"], axis=1)  \n",
    "    df = df.assign(d = df.d.str[2:].astype(int))\n",
    "    df = df.fillna(\"NoEvent\")\n",
    "    cols = list(set(df.columns) - {\"wm_yr_wk\", \"d\",\"snap_CA\",\"snap_TX\",\"snap_WI\"}) \n",
    "    oe = OrdinalEncoder(dtype=\"int\")\n",
    "    df[cols] = oe.fit_transform(df[cols])\n",
    "    pickle.dump(oe,encoder_file)\n",
    "    df = reduce_mem_usage(df)\n",
    "    return df\n",
    "\n",
    "calendar = prep_calendar(calendar,encoder_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 130.48 Mb (37.5% reduction)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Got from: [1]\n",
    "Originally, there were features added in this part. I excluded them until we decide whether to use those or not.\n",
    "'''\n",
    "def prep_selling_prices(df):\n",
    "    df = reduce_mem_usage(df)\n",
    "    return df\n",
    "\n",
    "selling_prices = prep_selling_prices(selling_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Got from: [1]\n",
    "- We drop the first \"drop_d\" days. Originally, this is set to 1000. When it is set to this value,\n",
    "  the shape we get 29,544,810 rows. When we don't set it, we get 60,034,810 rows. I think for now \n",
    "  we can keep this functionality, as it may be useful if we would like to discard some of the days.\n",
    "- In some id's, we have \"_validation\". Those are deleted.\n",
    "- reindex: Conform DataFrame to new index with optional filling logic (obtained from pandas doc). \n",
    "  We add days 1914+2*28 to prepare data from submission\n",
    "- We have to melt the sales dataframe since days are contained as columns.\n",
    "- assign: Returns a new object with all original columns in addition to new ones. Existing columns \n",
    "  that are re-assigned will be overwritten (obtained from pandas doc). Again, we make the values \n",
    "  \"d_1, d-2,...\" to \"1,2,...\"\n",
    "'''\n",
    "#We have to melt sales for sure because the days are columns, which is not desirable.\n",
    "def reshape_sales(df, drop_d = None):\n",
    "    if drop_d is not None:\n",
    "        df = df.drop([\"d_\" + str(i + 1) for i in range(drop_d)], axis=1)\n",
    "    df = df.assign(id=df.id.str.replace(\"_validation\", \"\"))\n",
    "    df = df.reindex(columns=df.columns.tolist() + [\"d_\" + str(1913 + i + 1) for i in range(2 * 28)])\n",
    "    df = df.melt(id_vars=[\"id\", \"item_id\", \"dept_id\", \"cat_id\", \"store_id\", \"state_id\"],\n",
    "                 var_name='d', value_name='demand')\n",
    "    df = df.assign(d=df.d.str[2:].astype(\"int16\"))\n",
    "    return df\n",
    "\n",
    "sales = reshape_sales(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = sales[sales.d.isin(calendar.d.unique())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d</th>\n",
       "      <th>demand</th>\n",
       "      <th>wday</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "      <th>daytype</th>\n",
       "      <th>sell_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1</td>\n",
       "      <td>HOBBIES_1_002</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1</td>\n",
       "      <td>HOBBIES_1_003</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004_CA_1</td>\n",
       "      <td>HOBBIES_1_004</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.339844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005_CA_1</td>\n",
       "      <td>HOBBIES_1_005</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id        item_id    dept_id   cat_id store_id state_id  \\\n",
       "0  HOBBIES_1_001_CA_1  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1       CA   \n",
       "1  HOBBIES_1_002_CA_1  HOBBIES_1_002  HOBBIES_1  HOBBIES     CA_1       CA   \n",
       "2  HOBBIES_1_003_CA_1  HOBBIES_1_003  HOBBIES_1  HOBBIES     CA_1       CA   \n",
       "3  HOBBIES_1_004_CA_1  HOBBIES_1_004  HOBBIES_1  HOBBIES     CA_1       CA   \n",
       "4  HOBBIES_1_005_CA_1  HOBBIES_1_005  HOBBIES_1  HOBBIES     CA_1       CA   \n",
       "\n",
       "    d  demand  wday  month  year  event_name_1  event_type_1  event_name_2  \\\n",
       "0  87     0.0     2      0     0             6             2             2   \n",
       "1  87     0.0     2      0     0             6             2             2   \n",
       "2  87     0.0     2      0     0             6             2             2   \n",
       "3  87     0.0     2      0     0             6             2             2   \n",
       "4  87     0.0     2      0     0             6             2             2   \n",
       "\n",
       "   event_type_2  snap_CA  snap_TX  snap_WI  daytype  sell_price  \n",
       "0             1        0        0        0        0         NaN  \n",
       "1             1        0        0        0        0         NaN  \n",
       "2             1        0        0        0        0         NaN  \n",
       "3             1        0        0        0        0    4.339844  \n",
       "4             1        0        0        0        0         NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Got from: [1]\n",
    "- Merge all the dataframes and delete the unnecessary ones\n",
    "- time.sleep() added to make sure garbage collector finishes its job before the next merge\n",
    "'''\n",
    "sales = sales.merge(calendar, how=\"left\", on=\"d\")\n",
    "del calendar\n",
    "gc.collect()\n",
    "time.sleep(5)\n",
    "sales = sales.merge(selling_prices, how=\"left\", on=[\"wm_yr_wk\", \"store_id\", \"item_id\"])\n",
    "del selling_prices\n",
    "sales.drop([\"wm_yr_wk\"], axis=1, inplace=True)\n",
    "gc.collect()\n",
    "time.sleep(5)\n",
    "sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.dropna(subset=[\"sell_price\"],inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d</th>\n",
       "      <th>demand</th>\n",
       "      <th>wday</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "      <th>daytype</th>\n",
       "      <th>sell_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004_CA_1</td>\n",
       "      <td>HOBBIES_1_004</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.339844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HOBBIES_1_008_CA_1</td>\n",
       "      <td>HOBBIES_1_008</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>87</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HOBBIES_1_009_CA_1</td>\n",
       "      <td>HOBBIES_1_009</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.769531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HOBBIES_1_010_CA_1</td>\n",
       "      <td>HOBBIES_1_010</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.169922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>HOBBIES_1_012_CA_1</td>\n",
       "      <td>HOBBIES_1_012</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>87</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.269531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id        item_id    dept_id   cat_id store_id state_id  \\\n",
       "3   HOBBIES_1_004_CA_1  HOBBIES_1_004  HOBBIES_1  HOBBIES     CA_1       CA   \n",
       "7   HOBBIES_1_008_CA_1  HOBBIES_1_008  HOBBIES_1  HOBBIES     CA_1       CA   \n",
       "8   HOBBIES_1_009_CA_1  HOBBIES_1_009  HOBBIES_1  HOBBIES     CA_1       CA   \n",
       "9   HOBBIES_1_010_CA_1  HOBBIES_1_010  HOBBIES_1  HOBBIES     CA_1       CA   \n",
       "11  HOBBIES_1_012_CA_1  HOBBIES_1_012  HOBBIES_1  HOBBIES     CA_1       CA   \n",
       "\n",
       "     d  demand  wday  month  year  event_name_1  event_type_1  event_name_2  \\\n",
       "3   87     0.0     2      0     0             6             2             2   \n",
       "7   87    10.0     2      0     0             6             2             2   \n",
       "8   87     0.0     2      0     0             6             2             2   \n",
       "9   87     0.0     2      0     0             6             2             2   \n",
       "11  87     1.0     2      0     0             6             2             2   \n",
       "\n",
       "    event_type_2  snap_CA  snap_TX  snap_WI  daytype  sell_price  \n",
       "3              1        0        0        0        0    4.339844  \n",
       "7              1        0        0        0        0    0.500000  \n",
       "8              1        0        0        0        0    1.769531  \n",
       "9              1        0        0        0        0    3.169922  \n",
       "11             1        0        0        0        0    6.269531  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode some variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 306.39 Mb (50.6% reduction)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Got from: [1]\n",
    "- We will also save the encoders in the pickle file.\n",
    "- The loop is slightly changed\n",
    "'''\n",
    "\n",
    "cat_id_cols = [\"item_id\", \"dept_id\", \"store_id\", \"cat_id\", \"state_id\"]\n",
    "\n",
    "# In loop to minimize memory use\n",
    "for col in cat_id_cols:\n",
    "    oe = OrdinalEncoder(dtype=\"int\")\n",
    "    sales[col] = oe.fit_transform(sales[[col]])\n",
    "    pickle.dump(oe,encoder_file)    \n",
    "sales = reduce_mem_usage(sales)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for col in sales.columns:\n",
    "#    if (col != 'd') and (col != 'id'):\n",
    "#        sales[col] = sales[col] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sales.loc[sales.sell_price.isna()] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d</th>\n",
       "      <th>demand</th>\n",
       "      <th>wday</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "      <th>daytype</th>\n",
       "      <th>sell_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004_CA_1</td>\n",
       "      <td>1440</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.339844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HOBBIES_1_008_CA_1</td>\n",
       "      <td>1444</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HOBBIES_1_009_CA_1</td>\n",
       "      <td>1445</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.769531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HOBBIES_1_010_CA_1</td>\n",
       "      <td>1446</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.169922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>HOBBIES_1_012_CA_1</td>\n",
       "      <td>1448</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.269531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id  item_id  dept_id  cat_id  store_id  state_id   d  \\\n",
       "3   HOBBIES_1_004_CA_1     1440        3       1         0         0  87   \n",
       "7   HOBBIES_1_008_CA_1     1444        3       1         0         0  87   \n",
       "8   HOBBIES_1_009_CA_1     1445        3       1         0         0  87   \n",
       "9   HOBBIES_1_010_CA_1     1446        3       1         0         0  87   \n",
       "11  HOBBIES_1_012_CA_1     1448        3       1         0         0  87   \n",
       "\n",
       "    demand  wday  month  year  event_name_1  event_type_1  event_name_2  \\\n",
       "3      0.0     2      0     0             6             2             2   \n",
       "7     10.0     2      0     0             6             2             2   \n",
       "8      0.0     2      0     0             6             2             2   \n",
       "9      0.0     2      0     0             6             2             2   \n",
       "11     1.0     2      0     0             6             2             2   \n",
       "\n",
       "    event_type_2  snap_CA  snap_TX  snap_WI  daytype  sell_price  \n",
       "3              1        0        0        0        0    4.339844  \n",
       "7              1        0        0        0        0    0.500000  \n",
       "8              1        0        0        0        0    1.769531  \n",
       "9              1        0        0        0        0    3.169922  \n",
       "11             1        0        0        0        0    6.269531  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we do train,test, validation split; for some time we have to store all data twice to be able to divide the dataset. And every feature we add increases the size of the dataset drastically. Hence, if you have memory issues, I would suggest doing this part after splitting, even if it means we have to execute each line 3 times (for train,test,valid). And we have to be careful for the first few rows because these features sometimes depend on previous datapoints; which may be found in train set for first few rows of validation, for example.\n",
    "\n",
    "KNN also may require some extra data storage. Moreover, in that case, this part can be even after KNN. This way, you can also use imputed selling prices to calculate your new features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Got from: [1]\n",
    "- These features were originally added in prep_selling_prices function to the \n",
    "  selling_prices dataframe, which does not exist anymore. But we can use the same\n",
    "  code to add these to sales dataframe as well as the columns are the same.\n",
    "- New feature=\"sell_price_rel_diff\"\n",
    "  pct_change(): Computes the percentage change from the immediately previous row by default. (Obtained from pandas doc.)\n",
    "  The two lines below adds the percentage of change of each item that is sold in the stores. Of course, for the\n",
    "  first datapoint, there is no previous, so this code produces an NA. Since there are 3049x10=30490 different (item,store)\n",
    "  pairs, this new column has 30490 NAs.\n",
    "- New feature=\"sell_price_roll_sd7\"\n",
    "  Rolling standard deviation: Moving Standard Deviation is a statistical measurement of market volatility (Google). We check the\n",
    "  past 7 days.\n",
    "- New feature=\"sell_price_cumrel\"\n",
    "  I think this is cumulative related frequency. I am not sure and I did not understand it clearly. I think\n",
    "  it is some kind of normalization, because we subtract the minimum and divide by max-min+1.\n",
    "- It runs without problems, but the RAM gets almost filled up so it gives you a heart attack.\n",
    "- No need to call reduce_mem_usage() after as I tried and it did not save any additional space.\n",
    "'''\n",
    "\n",
    "gr = sales.groupby([\"store_id\", \"item_id\"])[\"sell_price\"]\n",
    "sales[\"sell_price_rel_diff\"] = gr.pct_change()\n",
    "sales[\"sell_price_cumrel\"] = (gr.shift(0) - gr.cummin()) / (1 + gr.cummax() - gr.cummin())\n",
    "\n",
    "del gr\n",
    "gc.collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 416.37 Mb (0.0% reduction)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Got from: [1]\n",
    "Appearantly, [1] derived the features from [2].\n",
    "\n",
    "- The features include rolling means and standard deviations for different number of days.\n",
    "  I think this is also a measure of market volatiliy.\n",
    "- After this, original notebook deletes rows producing NAs. 'rolling_mean_t180' produces the most NAs as I\n",
    "  believe the value of first 180 days will be NA because to compute this we need 180 days prior. I do not \n",
    "  know whether adding these features is so important to delete that much data. Hence, I will keep it for now.\n",
    "  I think time ranges can also be changed.\n",
    "'''\n",
    "\n",
    "gr = sales.groupby([\"id\"])[\"demand\"]\n",
    "sales['lag_t28'] = gr.transform(lambda x: x.shift(28))\n",
    "sales['rolling_mean_t7'] = gr.transform(lambda x: x.shift(28).rolling(7).mean())\n",
    "sales['rolling_mean_t30'] = gr.transform(lambda x: x.shift(28).rolling(30).mean())\n",
    "#sales['rolling_mean_t60'] = gr.transform(lambda x: x.shift(28).rolling(60).mean())\n",
    "#sales['rolling_mean_t90'] = gr.transform(lambda x: x.shift(28).rolling(90).mean())\n",
    "#sales['rolling_mean_t180'] = gr.transform(lambda x: x.shift(28).rolling(180).mean())\n",
    "sales['rolling_std_t7'] = gr.transform(lambda x: x.shift(28).rolling(7).std())\n",
    "sales['rolling_std_t30'] = gr.transform(lambda x: x.shift(28).rolling(30).std())\n",
    "\n",
    "del gr\n",
    "sales = reduce_mem_usage(sales)\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naming convention:\n",
    "* test, train, valid -> Use these to create your X_{train,valid,test}  and y_{train,valid}.\n",
    "* Training data: X_train, y_train\n",
    "* Validation data: X_valid, y_valid\n",
    "* Testing data (Kaggle has the labels): X_test\n",
    "\n",
    "X_{train,valid,test} should be preprocessed according to your model.\n",
    "\n",
    "Since we will use test dataframe for submission and the submission is obtained from another person, make sure the order of X_test and test is the same.\n",
    "\n",
    "This process increases memory usage from 6GB to 7.5GB and reduce_mem_usage() does not improve the situation. One idea can be to keep the flags generated but produce end datasets at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Got from: [1]\n",
    "'''\n",
    "test = sales[sales.d >= 1914]\n",
    "test = test.assign(id=test.id + \"_\" + np.where(test.d <= 1941, \"validation\", \"evaluation\"),\n",
    "                   F=\"F\" + (test.d - 1913 - 28 * (test.d > 1941)).astype(\"str\"))\n",
    "gc.collect()\n",
    "\n",
    "# One month of validation data\n",
    "flag_valid = (sales.year == 4)\n",
    "valid = sales[flag_valid]\n",
    "flag_train = (sales.year < 4)\n",
    "train = sales[flag_train]\n",
    "\n",
    "\n",
    "del sales, flag_valid,flag_train\n",
    "gc.collect()\n",
    "time.sleep(5)\n",
    "\n",
    "test.reset_index(drop=True)\n",
    "valid.reset_index(drop=True)\n",
    "train.reset_index(drop=True)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impute NAs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentation says: If (selling_price) not available, this means that the product was not sold during the examined week. \n",
    "\n",
    "When we are not using recurrent structures, I think it is the\n",
    "best if we just remove those rows. However, for recurrent structures, such as LSTM and GRU, it would be better if\n",
    "the sequence was not broken. For those models, we can impute the missing labels with KNN. So there will be two\n",
    "alternatives. Set impute_labels=True to impute, False to drop depending on your application.\n",
    "\n",
    "Note that we have to do the imputation after we split the data to prevent leaking information.\n",
    "\n",
    "Don't use the demand column not to leak data from the label.\n",
    "\n",
    "I could not use KNN, SVR etc due to memory limitations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAs:\n",
      " id                           0\n",
      "item_id                      0\n",
      "dept_id                      0\n",
      "cat_id                       0\n",
      "store_id                     0\n",
      "state_id                     0\n",
      "d                            0\n",
      "demand                       0\n",
      "wday                         0\n",
      "month                        0\n",
      "year                         0\n",
      "event_name_1                 0\n",
      "event_type_1                 0\n",
      "event_name_2                 0\n",
      "event_type_2                 0\n",
      "snap_CA                      0\n",
      "snap_TX                      0\n",
      "snap_WI                      0\n",
      "daytype                      0\n",
      "sell_price                   0\n",
      "sell_price_rel_diff      28295\n",
      "sell_price_cumrel            0\n",
      "lag_t28                 788701\n",
      "rolling_mean_t7         956773\n",
      "rolling_mean_t30       1593829\n",
      "rolling_std_t7          956773\n",
      "rolling_std_t30        1593829\n",
      "dtype: int64\n",
      "0.0002539887197949281\n",
      "1.207188494891133\n",
      "1.4389886917412098\n",
      "1.5386993984260373\n",
      "1.5545478374307167\n",
      "1.5928540223901202\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"NAs:\\n\",train.isna().sum())\n",
    "impute_labels = True\n",
    "\n",
    "if not impute_labels:\n",
    "    train.dropna(inplace=True)\n",
    "    valid.dropna(inplace=True)\n",
    "    gc.collect()\n",
    "    time.sleep(2)\n",
    "else:\n",
    "    to_be_inputed = ['sell_price_rel_diff','rolling_std_t7','rolling_std_t30','lag_t28','rolling_mean_t7','rolling_mean_t30']\n",
    "    for col in to_be_inputed:\n",
    "        mean_train = train[col].dropna().astype(float).mean(skipna=True)\n",
    "        print(mean_train)\n",
    "        train[col] = train[col].fillna(mean_train)\n",
    "        valid[col] = valid[col].fillna(mean_train)\n",
    "        test[col] = test[col].fillna(mean_train)\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Close encoder file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Enter description of the model here **\n",
    "\n",
    "** Name your model \"model\" **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Dense, Input, Embedding, Dropout, concatenate, Flatten, LSTM, Reshape\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Got from: [1]\n",
    "Prepare X_{train,valid,test} and y_{train,valid}\n",
    "'''\n",
    "\n",
    "# Input dict for training with a dense array and separate inputs for each embedding input\n",
    "def make_X(df,dense_cols):\n",
    "    X = {\"dense1\": df[dense_cols].to_numpy()}\n",
    "    for i, v in enumerate(cat_cols):\n",
    "        X[v] = df[[v]].to_numpy()\n",
    "    return X\n",
    "\n",
    "cat_cols = [\"item_id\", \"dept_id\", \"store_id\", \"cat_id\", \"state_id\",\"wday\", \"month\", \"event_name_1\", \n",
    "            \"event_type_1\", \"event_name_2\", \"event_type_2\"]\n",
    "dense_cols = [\"lag_t28\",\"rolling_mean_t7\",\"rolling_mean_t30\",\"rolling_std_t7\",\"sell_price_rel_diff\",\n",
    "              \"rolling_std_t30\",\"snap_CA\", \"snap_TX\", \"snap_WI\",\"daytype\",\"year\"]\n",
    "\n",
    "X_test = make_X(test,dense_cols)\n",
    "X_train = make_X(train,dense_cols)\n",
    "y_train = train[\"demand\"]\n",
    "del train\n",
    "gc.collect()\n",
    "time.sleep(5)\n",
    "X_valid = make_X(valid,dense_cols)\n",
    "y_valid = valid[\"demand\"]\n",
    "del valid\n",
    "gc.collect()\n",
    "time.sleep(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Got from: [1]\n",
    "'''\n",
    "def create_model(lr=0.001):\n",
    "    tf.random.set_seed(173)\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "\n",
    "    # Dense input\n",
    "    dense_input = Input(shape=(len(dense_cols),), name='dense1')\n",
    "\n",
    "    # Embedding input\n",
    "    wday_input = Input(shape=(1,), name='wday')\n",
    "    month_input = Input(shape=(1,), name='month')\n",
    "    event_name_1_input = Input(shape=(1,), name='event_name_1')\n",
    "    event_type_1_input = Input(shape=(1,), name='event_type_1')\n",
    "    event_name_2_input = Input(shape=(1,), name='event_name_2')\n",
    "    event_type_2_input = Input(shape=(1,), name='event_type_2')\n",
    "    item_id_input = Input(shape=(1,), name='item_id')\n",
    "    dept_id_input = Input(shape=(1,), name='dept_id')\n",
    "    store_id_input = Input(shape=(1,), name='store_id')\n",
    "    cat_id_input = Input(shape=(1,), name='cat_id')\n",
    "    state_id_input = Input(shape=(1,), name='state_id')\n",
    "\n",
    "    wday_emb = Flatten()(Embedding(7, 1)(wday_input))\n",
    "    month_emb = Flatten()(Embedding(12, 1)(month_input))\n",
    "    event_name_1_emb = Flatten()(Embedding(31, 1)(event_name_1_input))\n",
    "    event_type_1_emb = Flatten()(Embedding(5, 1)(event_type_1_input))\n",
    "    event_name_2_emb = Flatten()(Embedding(5, 1)(event_name_2_input))\n",
    "    event_type_2_emb = Flatten()(Embedding(5, 1)(event_type_2_input))\n",
    "\n",
    "    item_id_emb = Flatten()(Embedding(3049, 3)(item_id_input))\n",
    "    dept_id_emb = Flatten()(Embedding(7, 1)(dept_id_input))\n",
    "    store_id_emb = Flatten()(Embedding(10, 1)(store_id_input))\n",
    "    cat_id_emb = Flatten()(Embedding(3, 1)(cat_id_input))\n",
    "    state_id_emb = Flatten()(Embedding(3, 1)(state_id_input))\n",
    "\n",
    "    # Combine dense and embedding parts and add dense layers. Exit on linear scale.\n",
    "    x = concatenate([dense_input, wday_emb, month_emb, \n",
    "                     event_name_1_emb, event_type_1_emb, \n",
    "                     event_name_2_emb, event_type_2_emb, \n",
    "                     item_id_emb, dept_id_emb, store_id_emb,\n",
    "                     cat_id_emb, state_id_emb])\n",
    "    x = Dense(150, activation=\"tanh\")(x)\n",
    "    x = Dense(75, activation=\"tanh\")(x)\n",
    "    x = Dense(10, activation=\"tanh\")(x)\n",
    "    outputs = Dense(1, activation=\"linear\", name='output')(x)\n",
    "\n",
    "    inputs = {\"dense1\": dense_input, \"wday\": wday_input, \"month\": month_input, \n",
    "              \"event_name_1\": event_name_1_input, \"event_type_1\": event_type_1_input,\n",
    "              \"event_name_2\": event_name_2_input, \"event_type_2\": event_type_2_input,\n",
    "              \"item_id\": item_id_input, \"dept_id\": dept_id_input, \"store_id\": store_id_input, \n",
    "              \"cat_id\": cat_id_input, \"state_id\": state_id_input}\n",
    "\n",
    "    # Connect input and output\n",
    "    model = Model(inputs, outputs)\n",
    "\n",
    "    model.compile(loss=keras.losses.mean_squared_error,\n",
    "                  metrics=[\"mse\"],\n",
    "                  optimizer=keras.optimizers.RMSprop(learning_rate=lr))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4839242 samples, validate on 1690962 samples\n",
      "Epoch 1/100\n",
      "4839242/4839242 [==============================] - 14s 3us/sample - loss: 17.7388 - mse: 17.7388 - val_loss: 10.3032 - val_mse: 10.3032\n",
      "Epoch 2/100\n",
      "4839242/4839242 [==============================] - 12s 3us/sample - loss: 16.4844 - mse: 16.4844 - val_loss: 9.8612 - val_mse: 9.8612\n",
      "Epoch 3/100\n",
      "4839242/4839242 [==============================] - 12s 3us/sample - loss: 15.5704 - mse: 15.5704 - val_loss: 9.5129 - val_mse: 9.5129\n",
      "Epoch 4/100\n",
      "4839242/4839242 [==============================] - 12s 3us/sample - loss: 14.9502 - mse: 14.9502 - val_loss: 9.2310 - val_mse: 9.2310\n",
      "Epoch 5/100\n",
      "4839242/4839242 [==============================] - 12s 3us/sample - loss: 14.4381 - mse: 14.4381 - val_loss: 8.9684 - val_mse: 8.9684\n",
      "Epoch 6/100\n",
      "4839242/4839242 [==============================] - 13s 3us/sample - loss: 13.9937 - mse: 13.9937 - val_loss: 8.7645 - val_mse: 8.7645\n",
      "Epoch 7/100\n",
      "4839242/4839242 [==============================] - 12s 3us/sample - loss: 13.6067 - mse: 13.6067 - val_loss: 8.6204 - val_mse: 8.6204\n",
      "Epoch 8/100\n",
      "4839242/4839242 [==============================] - 12s 3us/sample - loss: 13.2669 - mse: 13.2669 - val_loss: 8.4756 - val_mse: 8.4756\n",
      "Epoch 9/100\n",
      "4839242/4839242 [==============================] - 12s 2us/sample - loss: 12.9726 - mse: 12.9726 - val_loss: 8.3805 - val_mse: 8.3805\n",
      "Epoch 10/100\n",
      "4839242/4839242 [==============================] - 12s 3us/sample - loss: 12.7092 - mse: 12.7092 - val_loss: 8.2892 - val_mse: 8.2892\n",
      "Epoch 11/100\n",
      "4839242/4839242 [==============================] - 12s 3us/sample - loss: 12.4764 - mse: 12.4764 - val_loss: 8.1674 - val_mse: 8.1674\n",
      "Epoch 12/100\n",
      "4839242/4839242 [==============================] - 12s 3us/sample - loss: 12.2675 - mse: 12.2675 - val_loss: 8.0755 - val_mse: 8.0755\n",
      "Epoch 13/100\n",
      "4839242/4839242 [==============================] - 12s 3us/sample - loss: 12.0766 - mse: 12.0766 - val_loss: 8.0176 - val_mse: 8.0176\n",
      "Epoch 14/100\n",
      "4839242/4839242 [==============================] - 12s 2us/sample - loss: 11.9041 - mse: 11.9041 - val_loss: 7.9368 - val_mse: 7.9368\n",
      "Epoch 15/100\n",
      "4839242/4839242 [==============================] - 12s 3us/sample - loss: 11.7475 - mse: 11.7475 - val_loss: 7.8726 - val_mse: 7.8726\n",
      "Epoch 16/100\n",
      "4839242/4839242 [==============================] - 12s 3us/sample - loss: 11.6020 - mse: 11.6020 - val_loss: 7.9198 - val_mse: 7.9198\n",
      "Epoch 17/100\n",
      "4839242/4839242 [==============================] - 12s 3us/sample - loss: 11.4691 - mse: 11.4691 - val_loss: 7.8782 - val_mse: 7.8782\n",
      "Epoch 18/100\n",
      "4839242/4839242 [==============================] - 12s 3us/sample - loss: 11.3472 - mse: 11.3472 - val_loss: 7.7598 - val_mse: 7.7598\n",
      "Epoch 19/100\n",
      "4839242/4839242 [==============================] - 12s 2us/sample - loss: 11.2371 - mse: 11.2371 - val_loss: 7.8090 - val_mse: 7.8090\n",
      "Epoch 20/100\n",
      "4839242/4839242 [==============================] - 12s 3us/sample - loss: 11.1322 - mse: 11.1322 - val_loss: 7.7833 - val_mse: 7.7833\n",
      "Epoch 21/100\n",
      "4839242/4839242 [==============================] - 12s 3us/sample - loss: 11.0377 - mse: 11.0377 - val_loss: 7.7492 - val_mse: 7.7492\n",
      "Epoch 22/100\n",
      "4839242/4839242 [==============================] - 12s 3us/sample - loss: 10.9457 - mse: 10.9457 - val_loss: 7.7626 - val_mse: 7.7626\n",
      "Epoch 23/100\n",
      "4839242/4839242 [==============================] - 12s 3us/sample - loss: 10.8607 - mse: 10.8607 - val_loss: 7.6591 - val_mse: 7.6591\n",
      "Epoch 24/100\n",
      "4839242/4839242 [==============================] - 12s 2us/sample - loss: 10.7818 - mse: 10.7818 - val_loss: 7.6797 - val_mse: 7.6797\n",
      "Epoch 25/100\n",
      "4839242/4839242 [==============================] - 12s 3us/sample - loss: 10.7062 - mse: 10.7062 - val_loss: 7.6702 - val_mse: 7.6702\n",
      "Epoch 26/100\n",
      "4839242/4839242 [==============================] - 12s 3us/sample - loss: 10.6316 - mse: 10.6316 - val_loss: 7.6509 - val_mse: 7.6509\n",
      "Epoch 27/100\n",
      "4839242/4839242 [==============================] - 12s 3us/sample - loss: 10.5600 - mse: 10.5600 - val_loss: 7.6206 - val_mse: 7.6206\n",
      "Epoch 28/100\n",
      "4839242/4839242 [==============================] - 12s 2us/sample - loss: 10.4922 - mse: 10.4922 - val_loss: 7.5987 - val_mse: 7.5987\n",
      "Epoch 29/100\n",
      "4839242/4839242 [==============================] - 12s 2us/sample - loss: 10.4300 - mse: 10.4300 - val_loss: 7.6340 - val_mse: 7.6340\n",
      "Epoch 30/100\n",
      "4839242/4839242 [==============================] - 12s 2us/sample - loss: 10.1830 - mse: 10.1830 - val_loss: 7.5656 - val_mse: 7.5656\n",
      "Epoch 34/100\n",
      "4839242/4839242 [==============================] - 12s 2us/sample - loss: 10.1231 - mse: 10.1231 - val_loss: 7.4757 - val_mse: 7.4757\n",
      "Epoch 35/100\n",
      "4839242/4839242 [==============================] - 12s 3us/sample - loss: 10.0670 - mse: 10.0670 - val_loss: 7.5796 - val_mse: 7.5796\n",
      "Epoch 36/100\n",
      "4839242/4839242 [==============================] - 18s 4us/sample - loss: 10.0094 - mse: 10.0094 - val_loss: 7.6075 - val_mse: 7.6075\n",
      "Epoch 37/100\n",
      "4839242/4839242 [==============================] - 12s 2us/sample - loss: 9.9526 - mse: 9.9526 - val_loss: 7.5545 - val_mse: 7.5545\n",
      "Epoch 38/100\n",
      "4839242/4839242 [==============================] - 12s 2us/sample - loss: 9.8948 - mse: 9.8948 - val_loss: 7.5373 - val_mse: 7.5373\n",
      "Epoch 39/100\n",
      "4839242/4839242 [==============================] - 12s 3us/sample - loss: 9.8327 - mse: 9.8327 - val_loss: 7.5652 - val_mse: 7.5652\n",
      "Epoch 40/100\n",
      "4839242/4839242 [==============================] - 12s 2us/sample - loss: 9.7767 - mse: 9.7767 - val_loss: 7.6015 - val_mse: 7.6015\n",
      "Epoch 41/100\n",
      "4839242/4839242 [==============================] - 12s 2us/sample - loss: 9.7170 - mse: 9.7170 - val_loss: 7.5915 - val_mse: 7.5915\n",
      "Epoch 42/100\n",
      "4839242/4839242 [==============================] - 12s 2us/sample - loss: 9.6633 - mse: 9.6633 - val_loss: 7.5690 - val_mse: 7.5690\n",
      "Epoch 43/100\n",
      "4839242/4839242 [==============================] - 12s 3us/sample - loss: 9.6115 - mse: 9.6115 - val_loss: 7.5764 - val_mse: 7.5764\n",
      "Epoch 44/100\n",
      "4839242/4839242 [==============================] - 12s 3us/sample - loss: 9.5633 - mse: 9.5633 - val_loss: 7.5700 - val_mse: 7.5700\n",
      "Epoch 45/100\n",
      "4839242/4839242 [==============================] - 12s 2us/sample - loss: 9.5164 - mse: 9.5164 - val_loss: 7.6100 - val_mse: 7.6100\n",
      "Epoch 46/100\n",
      "4839242/4839242 [==============================] - 12s 3us/sample - loss: 9.4683 - mse: 9.4683 - val_loss: 7.6264 - val_mse: 7.6264\n",
      "Epoch 47/100\n",
      "4839242/4839242 [==============================] - 12s 2us/sample - loss: 9.4263 - mse: 9.4263 - val_loss: 7.7289 - val_mse: 7.7289\n",
      "Epoch 48/100\n",
      "4839242/4839242 [==============================] - 12s 2us/sample - loss: 9.3900 - mse: 9.3900 - val_loss: 7.6264 - val_mse: 7.6264\n",
      "Epoch 49/100\n",
      "4839242/4839242 [==============================] - 12s 3us/sample - loss: 9.3519 - mse: 9.3519 - val_loss: 7.7916 - val_mse: 7.7916\n",
      "Epoch 50/100\n",
      "4839242/4839242 [==============================] - 12s 2us/sample - loss: 9.3154 - mse: 9.3154 - val_loss: 7.7589 - val_mse: 7.7589\n",
      "Epoch 51/100\n",
      "4839242/4839242 [==============================] - 12s 2us/sample - loss: 9.2837 - mse: 9.2837 - val_loss: 7.6965 - val_mse: 7.6965\n",
      "Epoch 52/100\n",
      "4839242/4839242 [==============================] - 12s 2us/sample - loss: 9.2494 - mse: 9.2494 - val_loss: 7.7600 - val_mse: 7.7600\n",
      "Epoch 53/100\n",
      "4839242/4839242 [==============================] - 12s 2us/sample - loss: 9.2200 - mse: 9.2200 - val_loss: 7.7968 - val_mse: 7.7968\n",
      "Epoch 54/100\n",
      "4839242/4839242 [==============================] - 12s 3us/sample - loss: 9.1932 - mse: 9.1932 - val_loss: 7.8497 - val_mse: 7.8497\n",
      "Epoch 55/100\n",
      "4839242/4839242 [==============================] - 12s 2us/sample - loss: 9.1591 - mse: 9.1591 - val_loss: 7.7983 - val_mse: 7.7984\n",
      "Epoch 56/100\n",
      "4839242/4839242 [==============================] - 12s 3us/sample - loss: 9.1328 - mse: 9.1328 - val_loss: 7.9856 - val_mse: 7.9856\n",
      "Epoch 57/100\n",
      "4839242/4839242 [==============================] - 12s 2us/sample - loss: 9.1025 - mse: 9.1025 - val_loss: 7.8412 - val_mse: 7.8412\n",
      "Epoch 58/100\n",
      "4839242/4839242 [==============================] - 12s 2us/sample - loss: 9.0749 - mse: 9.0749 - val_loss: 7.9481 - val_mse: 7.9481\n",
      "Epoch 59/100\n",
      "4839242/4839242 [==============================] - 13s 3us/sample - loss: 8.7278 - mse: 8.7278 - val_loss: 8.7407 - val_mse: 8.7407\n",
      "Epoch 75/100\n",
      "4839242/4839242 [==============================] - 12s 2us/sample - loss: 8.7131 - mse: 8.7131 - val_loss: 9.0486 - val_mse: 9.0486\n",
      "Epoch 76/100\n",
      "4839242/4839242 [==============================] - 12s 2us/sample - loss: 8.6962 - mse: 8.6962 - val_loss: 9.1821 - val_mse: 9.1821\n",
      "Epoch 77/100\n",
      "4839242/4839242 [==============================] - 12s 2us/sample - loss: 8.6767 - mse: 8.6767 - val_loss: 9.4703 - val_mse: 9.4703\n",
      "Epoch 78/100\n",
      "4839242/4839242 [==============================] - 12s 2us/sample - loss: 8.6592 - mse: 8.6592 - val_loss: 9.3019 - val_mse: 9.3019\n",
      "Epoch 79/100\n",
      "4839242/4839242 [==============================] - 12s 3us/sample - loss: 8.6429 - mse: 8.6429 - val_loss: 9.0089 - val_mse: 9.0089\n",
      "Epoch 80/100\n",
      "4839242/4839242 [==============================] - 17s 3us/sample - loss: 8.6275 - mse: 8.6275 - val_loss: 9.2391 - val_mse: 9.2391\n",
      "Epoch 81/100\n",
      "4839242/4839242 [==============================] - 12s 3us/sample - loss: 8.6117 - mse: 8.6117 - val_loss: 9.8601 - val_mse: 9.8601\n",
      "Epoch 82/100\n",
      "4839242/4839242 [==============================] - 13s 3us/sample - loss: 8.5944 - mse: 8.5944 - val_loss: 9.6988 - val_mse: 9.6988\n",
      "Epoch 83/100\n",
      "4839242/4839242 [==============================] - 12s 3us/sample - loss: 8.5762 - mse: 8.5762 - val_loss: 9.2218 - val_mse: 9.2218\n",
      "Epoch 84/100\n",
      "4839242/4839242 [==============================] - 13s 3us/sample - loss: 8.5597 - mse: 8.5597 - val_loss: 9.5125 - val_mse: 9.5125\n",
      "Epoch 85/100\n",
      "4839242/4839242 [==============================] - 12s 3us/sample - loss: 8.5468 - mse: 8.5468 - val_loss: 10.2908 - val_mse: 10.2908\n",
      "Epoch 86/100\n",
      "4839242/4839242 [==============================] - 12s 3us/sample - loss: 8.5274 - mse: 8.5274 - val_loss: 10.0750 - val_mse: 10.0750\n",
      "Epoch 87/100\n",
      "4839242/4839242 [==============================] - 12s 3us/sample - loss: 8.5129 - mse: 8.5129 - val_loss: 10.8586 - val_mse: 10.8586\n",
      "Epoch 88/100\n",
      "4839242/4839242 [==============================] - 12s 3us/sample - loss: 8.4997 - mse: 8.4996 - val_loss: 10.6298 - val_mse: 10.6299\n",
      "Epoch 89/100\n",
      "4839242/4839242 [==============================] - 12s 3us/sample - loss: 8.4838 - mse: 8.4838 - val_loss: 9.8490 - val_mse: 9.8490\n",
      "Epoch 90/100\n",
      "4839242/4839242 [==============================] - 12s 3us/sample - loss: 8.4725 - mse: 8.4725 - val_loss: 10.1647 - val_mse: 10.1647\n",
      "Epoch 91/100\n",
      "4839242/4839242 [==============================] - 12s 3us/sample - loss: 8.4545 - mse: 8.4545 - val_loss: 9.9215 - val_mse: 9.9215\n",
      "Epoch 92/100\n",
      "4839242/4839242 [==============================] - 12s 3us/sample - loss: 8.4366 - mse: 8.4366 - val_loss: 11.0464 - val_mse: 11.0464\n",
      "Epoch 93/100\n",
      "4839242/4839242 [==============================] - 12s 3us/sample - loss: 8.4252 - mse: 8.4252 - val_loss: 10.5298 - val_mse: 10.5298\n",
      "Epoch 94/100\n",
      "4839242/4839242 [==============================] - 12s 3us/sample - loss: 8.4111 - mse: 8.4111 - val_loss: 10.1833 - val_mse: 10.1833\n",
      "Epoch 95/100\n",
      "4839242/4839242 [==============================] - 12s 3us/sample - loss: 8.3908 - mse: 8.3908 - val_loss: 10.9756 - val_mse: 10.9756\n",
      "Epoch 96/100\n",
      "4839242/4839242 [==============================] - 12s 3us/sample - loss: 8.3858 - mse: 8.3858 - val_loss: 10.9955 - val_mse: 10.9955\n",
      "Epoch 97/100\n",
      "4839242/4839242 [==============================] - 12s 3us/sample - loss: 8.3692 - mse: 8.3692 - val_loss: 10.7019 - val_mse: 10.7019\n",
      "Epoch 98/100\n",
      "4839242/4839242 [==============================] - 13s 3us/sample - loss: 8.3530 - mse: 8.3530 - val_loss: 10.1536 - val_mse: 10.1536\n",
      "Epoch 99/100\n",
      "4839242/4839242 [==============================] - 12s 3us/sample - loss: 8.3430 - mse: 8.3430 - val_loss: 10.8311 - val_mse: 10.8311\n",
      "Epoch 100/100\n",
      "4839242/4839242 [==============================] - 12s 3us/sample - loss: 8.3298 - mse: 8.3298 - val_loss: 11.0081 - val_mse: 11.0081\n"
     ]
    }
   ],
   "source": [
    "model = create_model(0.0002)\n",
    "history = model.fit(X_train, y_train,batch_size=10000,epochs=100,shuffle=True,\n",
    "                    validation_data=[X_valid,y_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "Got from: [1]\n",
    "'''\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Got from: [1]\n",
    "'''\n",
    "pred = model.predict(X_test)\n",
    "test[\"demand\"] = pred.clip(0)\n",
    "submission = test.pivot(index=\"id\", columns=\"F\", values=\"demand\").reset_index()[sample_submission.columns]\n",
    "submission = sample_submission[[\"id\"]].merge(submission, how=\"left\", on=\"id\")\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
